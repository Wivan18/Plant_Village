{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Splitting the data to train, test and alidation\n",
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# # Define the source directory where the images are found\n",
    "# source_dir = r\"D:\\Data_Science_Projects\\PlantVillage\"\n",
    "\n",
    "# # Define the base directory where the organized folders will be saved\n",
    "# base_dir = r\"D:\\Data_Science_Projects\\PlantVillage2\"\n",
    "\n",
    "# # Define the subdirectories containing the images\n",
    "# subdirectories = [\n",
    "#     'Pepper__bell___Bacterial_spot',\n",
    "#     'Pepper__bell___healthy',\n",
    "#     'Potato___Early_blight',\n",
    "#     'Potato___healthy',\n",
    "#     'Potato___Late_blight',\n",
    "#     'Tomato_Bacterial_spot',\n",
    "#     'Tomato_Early_blight',\n",
    "#     'Tomato_healthy',\n",
    "#     'Tomato_Late_blight',\n",
    "#     'Tomato_Leaf_Mold',\n",
    "#     'Tomato_Septoria_leaf_spot',\n",
    "#     'Tomato_Spider_mites_Two_spotted_spider_mite',\n",
    "#     'Tomato__Target_Spot',\n",
    "#     'Tomato__Tomato_mosaic_virus',\n",
    "#     'Tomato__Tomato_YellowLeaf__Curl_Virus'\n",
    "# ]\n",
    "\n",
    "# # Create the train, validation, and test directories if they do not exist\n",
    "# os.makedirs(os.path.join(base_dir, 'train'), exist_ok=True)\n",
    "# os.makedirs(os.path.join(base_dir, 'validation'), exist_ok=True)\n",
    "# os.makedirs(os.path.join(base_dir, 'test'), exist_ok=True)\n",
    "\n",
    "# # Define the distribution ratios\n",
    "# train_ratio = 0.7\n",
    "# validation_ratio = 0.15\n",
    "# test_ratio = 0.15\n",
    "\n",
    "# # Iterate through each subdirectory\n",
    "# for subdirectory in subdirectories:\n",
    "#     source_path = os.path.join(source_dir, subdirectory)\n",
    "\n",
    "#     # List all files in the source directory\n",
    "#     files = os.listdir(source_path)\n",
    "\n",
    "#     # Calculate the number of files for each split\n",
    "#     total_files = len(files)\n",
    "#     train_count = int(train_ratio * total_files)\n",
    "#     validation_count = int(validation_ratio * total_files)\n",
    "\n",
    "#     # Shuffle files and split into train, validation, and test sets\n",
    "#     shuffled_files = files[:]  # Create a copy of the file list\n",
    "#     random.shuffle(shuffled_files)  # Shuffle the list of files\n",
    "\n",
    "#     # Create subdirectories for each category in the base directory\n",
    "#     os.makedirs(os.path.join(base_dir, 'train', subdirectory), exist_ok=True)\n",
    "#     os.makedirs(os.path.join(base_dir, 'validation', subdirectory), exist_ok=True)\n",
    "#     os.makedirs(os.path.join(base_dir, 'test', subdirectory), exist_ok=True)\n",
    "\n",
    "#     # Move files to respective folders\n",
    "#     for i, file in enumerate(shuffled_files):\n",
    "#         if i < train_count:\n",
    "#             shutil.move(os.path.join(source_path, file), os.path.join(base_dir, 'train', subdirectory, file))\n",
    "#         elif i < train_count + validation_count:\n",
    "#             shutil.move(os.path.join(source_path, file), os.path.join(base_dir, 'validation', subdirectory, file))\n",
    "#         else:\n",
    "#             shutil.move(os.path.join(source_path, file), os.path.join(base_dir, 'test', subdirectory, file))\n",
    "\n",
    "# print(\"Data has been organized into train, validation, and test folders.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have been resized.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Define the base directory and target size\n",
    "base_dir = r\"D:\\Data_Science_Projects\\PlantVillage2\"\n",
    "target_size = (224, 224)  # Define your target size\n",
    "\n",
    "# Function to resize images\n",
    "def resize_images(base_directory):\n",
    "    for dataset in ['train', 'validation', 'test']:\n",
    "        directory = os.path.join(base_directory, dataset)\n",
    "        for subdir, _, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                with Image.open(file_path) as img:\n",
    "                    img = img.resize(target_size)\n",
    "                    img.save(file_path)  # Overwrite the original image\n",
    "\n",
    "# Resize images in all directories\n",
    "resize_images(base_dir)\n",
    "print(\"Images have been resized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have been normalized.\n"
     ]
    }
   ],
   "source": [
    "#Normalization of images\n",
    "import numpy as np\n",
    "\n",
    "# Function to normalize images\n",
    "def normalize_images(base_directory):\n",
    "    for dataset in ['train', 'validation', 'test']:\n",
    "        directory = os.path.join(base_directory, dataset)\n",
    "        for subdir, _, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                with Image.open(file_path) as img:\n",
    "                    img_array = np.array(img) / 255.0  # Normalize pixel values\n",
    "                    img_array = (img_array * 255).astype(np.uint8)  # Convert back to uint8\n",
    "                    img = Image.fromarray(img_array)\n",
    "                    img.save(file_path)  # Overwrite the original image\n",
    "\n",
    "# Normalize images in all directories\n",
    "normalize_images(base_dir)\n",
    "print(\"Images have been normalized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation for training set completed.\n"
     ]
    }
   ],
   "source": [
    "#Data Augmentation\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the data augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to perform data augmentation\n",
    "def augment_images(base_directory, save_to_directory):\n",
    "    train_dir = os.path.join(base_directory, 'train')\n",
    "    for subdir, _, files in os.walk(train_dir):\n",
    "        class_name = os.path.basename(subdir)\n",
    "        os.makedirs(os.path.join(save_to_directory, class_name), exist_ok=True)  # Create class folder\n",
    "\n",
    "        for file in files:\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            img = tf.keras.preprocessing.image.load_img(file_path)\n",
    "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "            # Generate augmented images\n",
    "            i = 0\n",
    "            for batch in datagen.flow(img_array, batch_size=1, save_to_dir=os.path.join(save_to_directory, class_name), save_prefix='aug', save_format='jpeg'):\n",
    "                i += 1\n",
    "                if i >= 5:  # Limit to 5 augmented images per original\n",
    "                    break\n",
    "\n",
    "# Create a directory for augmented images\n",
    "augmented_dir = r\"D:\\Data_Science_Projects\\PlantVillage2\\augmented\"\n",
    "augment_images(base_dir, augmented_dir)\n",
    "print(\"Data augmentation for training set completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping through various models to find the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, VGG19, ResNet50, EfficientNetB0, MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14441 images belonging to 15 classes.\n",
      "Found 3088 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "#Data Preprocessing\n",
    "# Directories\n",
    "base_dir = r\"D:\\Data_Science_Projects\\PlantVillage2\"\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,  # Normalize pixel values\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# Data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Build and Compile Models\n",
    "def build_model(model_name, input_shape=(224, 224, 3), num_classes=10):\n",
    "    if model_name == 'CNN':\n",
    "        model = Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "    elif model_name == 'VGG16':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        model = Sequential([base_model, GlobalAveragePooling2D(), Dense(256, activation='relu'), Dense(num_classes, activation='softmax')])\n",
    "    elif model_name == 'VGG19':\n",
    "        base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        model = Sequential([base_model, GlobalAveragePooling2D(), Dense(256, activation='relu'), Dense(num_classes, activation='softmax')])\n",
    "    elif model_name == 'ResNet':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        model = Sequential([base_model, GlobalAveragePooling2D(), Dense(256, activation='relu'), Dense(num_classes, activation='softmax')])\n",
    "    elif model_name == 'EfficientNet':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        model = Sequential([base_model, GlobalAveragePooling2D(), Dense(256, activation='relu'), Dense(num_classes, activation='softmax')])\n",
    "    elif model_name == 'MobileNet':\n",
    "        base_model = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "        model = Sequential([base_model, GlobalAveragePooling2D(), Dense(256, activation='relu'), Dense(num_classes, activation='softmax')])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a Function to Calculate Metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried the following models:\n",
    "\n",
    "CNN\n",
    "VGG16/19\n",
    "ResNet\n",
    "EfficientNet\n",
    "MobileNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train and Evaluate Models in a Loop\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# models = ['MobileNet', 'CNN']\n",
    "# best_model = None\n",
    "# best_f1_score = 0\n",
    "\n",
    "# # Store results for each model\n",
    "# results = {}\n",
    "\n",
    "# # Loop through each model\n",
    "# for model_name in models:\n",
    "#     print(f\"\\nTraining {model_name} model...\")\n",
    "    \n",
    "#     # Build the model\n",
    "#     model = build_model(model_name, num_classes=train_generator.num_classes)\n",
    "    \n",
    "#     # Train the model\n",
    "#     model.fit(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "#         validation_data=validation_generator,\n",
    "#         validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "#         epochs=3  # You can increase this if needed\n",
    "#     )\n",
    "    \n",
    "#     # Predict on validation data\n",
    "#     validation_generator.reset()\n",
    "#     predictions = model.predict(validation_generator)\n",
    "#     y_pred = np.argmax(predictions, axis=1)\n",
    "    \n",
    "#     # True labels\n",
    "#     y_true = validation_generator.classes\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     accuracy, precision, recall, f1, cm = calculate_metrics(y_true, y_pred)\n",
    "    \n",
    "#     # Print the metrics\n",
    "#     print(f\"\\nResults for {model_name}:\")\n",
    "#     print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "#     print(f\"Precision: {precision:.2f}\")\n",
    "#     print(f\"Recall: {recall:.2f}\")\n",
    "#     print(f\"F1 Score: {f1:.2f}\")\n",
    "#     print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    \n",
    "#     # Store the results\n",
    "#     results[model_name] = {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1, 'confusion_matrix': cm}\n",
    "    \n",
    "#     # Keep track of the best model based on F1 score\n",
    "#     if f1 > best_f1_score:\n",
    "#         best_f1_score = f1\n",
    "#         best_model = model_name\n",
    "\n",
    "# print(f\"\\nThe best model is {best_model} with an F1 score of {best_f1_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for CNN:\n",
    "Accuracy: 71.89%\n",
    "Precision: 0.78\n",
    "Recall: 0.72\n",
    "F1 Score: 0.71\n",
    "Confusion Matrix:\n",
    "[[126   6   0   0   5   0   0   0   1   7   2   2   0   0   0]\n",
    " [ 18 169   0   0  19   0   0   0   0   3   0   8   3   0   1]\n",
    " [  1   0 133   1   0   0   0   0   0   3   0   2   0   0  10]\n",
    " [  2   0   9 110  10   0   0   0   0   5   6   7   1   0   0]\n",
    " [  1   0   0   0  20   0   0   0   0   0   0   1   0   0   0]\n",
    " [  1   1   0  15   6 237   0   1   0   4   1  14  39   0   0]\n",
    " [ 14   2   3  15   0  19  34   5   0   7  16  20  12   0   3]\n",
    " [ 29   3  17  36   2   3   2 114   1  49   8   4   8   0  10]\n",
    " [ 20   0   4   0   4   1   0   4  36  32  13   3   0   6  19]\n",
    " [  7   2   4   2  23   2   0   0   0 177   1   5   4   8  30]\n",
    " [  6   0   0   2   4   0   0   0   0   0 208  25   2   0   4]\n",
    " [  0   0   0   3   8   0   0   0   0   0  19 142   0   0  38]\n",
    " [ 18   0   0   0   3   1   0   0   0   0  24   0 434   0   0]\n",
    " [  0   0   0   0   0   0   0   0   0   0   4   8   0  42   1]\n",
    " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 238]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for MobileNet:\n",
    "Accuracy: 90.22%\n",
    "Precision: 0.92\n",
    "Recall: 0.90\n",
    "F1 Score: 0.90\n",
    "Confusion Matrix:\n",
    "[[146   2   0   0   0   0   0   0   0   0   0   0   1   0   0]\n",
    " [  2 216   0   0   0   0   0   0   0   0   0   0   3   0   0]\n",
    " [  0   0 149   0   0   0   0   0   0   1   0   0   0   0   0]\n",
    " [  0   1   0 136   0   0   1  12   0   0   0   0   0   0   0]\n",
    " [  0   7   0   0  14   0   0   0   0   0   0   0   0   1   0]\n",
    " [  9   0   0   0   0 263   6   0   2   4   0   3  32   0   0]\n",
    " [  0   0   0   0   0   0 128   8   1  12   0   0   0   1   0]\n",
    " [  0   0   0   0   0   1   2 270  11   2   0   0   0   0   0]\n",
    " [  0   1   0   0   0   0   0   0 134   1   0   0   0   6   0]\n",
    " [  0   0   0   0   0   0   1   0   6 255   0   0   0   3   0]\n",
    " [  0   1   0   0   0   0   2   0   1   0 229   0   7  11   0]\n",
    " [  3   1   0   0   0   0   3   2   2  37  26 111   7  18   0]\n",
    " [  0   0   0   0   0   0   0   0   0   0   0   0 480   0   0]\n",
    " [  0   0   0   0   0   0   0   0   0   0   0   0   0  55   0]\n",
    " [  0   1   0   0   0   2   0   1   0  23   6   1   2   2 200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_Science_Projects\\env\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_Science_Projects\\env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1267s\u001b[0m 3s/step - accuracy: 0.1979 - loss: 2.5098 - val_accuracy: 0.3952 - val_loss: 1.8996\n",
      "Epoch 2/5\n",
      "\u001b[1m  1/451\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:09\u001b[0m 2s/step - accuracy: 0.2812 - loss: 2.3144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wivan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 623us/step - accuracy: 0.2812 - loss: 2.3144 - val_accuracy: 0.8125 - val_loss: 1.8009\n",
      "Epoch 3/5\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1067s\u001b[0m 2s/step - accuracy: 0.3782 - loss: 1.9438 - val_accuracy: 0.6038 - val_loss: 1.1971\n",
      "Epoch 4/5\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 563us/step - accuracy: 0.4375 - loss: 1.5253 - val_accuracy: 1.0000 - val_loss: 0.5483\n",
      "Epoch 5/5\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1089s\u001b[0m 2s/step - accuracy: 0.5137 - loss: 1.4699 - val_accuracy: 0.7038 - val_loss: 0.8629\n",
      "\n",
      "Evaluating CNN model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Evaluate CNN model\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating CNN model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m cnn_accuracy, cnn_precision, cnn_recall, cnn_f1, cnn_cm \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m(cnn_model, validation_generator)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate_model' is not defined"
     ]
    }
   ],
   "source": [
    "#CNN model\n",
    "# CNN Model Function\n",
    "from tensorflow.keras.models import Model\n",
    "def build_cnn(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))# 32 filters - can be tweaked to incerase the variety of features learnt, 3x3 kernel, ReLU activation\n",
    "    model.add(layers.MaxPooling2D((2, 2))) # (2,2) - Pooling sizes -reduces the spatial dimensions of the feature maps, retaining only the most prominent features (reducing the complexity).\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))# Increasing layers and filters (64)  we allow the network to capture a richer and more diverse set of features.\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))# Increasing layers and filters (128)  we allow the network to capture a richer and more diverse set of features.\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flatten and fully connected layers\n",
    "    model.add(layers.Flatten()) # Flattens the 3D output from the last convolutional layer into a 1D array\n",
    "    model.add(layers.Dense(128, activation='relu')) # This adds a fully connected layer with 128 neurons. Adjusting this number can affect how much information the model can learn\n",
    "    model.add(layers.Dropout(0.5)) # This randomly drops 50% of the neurons during training to prevent overfitting.\n",
    "    model.add(layers.Dense(num_classes, activation='softmax')) # This final layer outputs probabilities for each class using the softmax activation function. The number of neurons here should match your number of classes.( Thus num_classes)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',  # The Adam optimizer is used here, which adapts the learning rate during training. You can experiment with different optimizers like SGD, RMSprop, etc., and adjust their learning rates to improve performance.\n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train CNN\n",
    "print(\"Training CNN model...\")\n",
    "\n",
    "# Build the CNN model\n",
    "cnn_model = build_cnn(input_shape=(224, 224, 3), num_classes=train_generator.num_classes)\n",
    "\n",
    "# Train the CNN model\n",
    "cnn_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=5  # Adjust this based on training performance\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, validation_generator):\n",
    "    # Predict on validation data\n",
    "    validation_generator.reset()  # Reset the generator to avoid any partial batches\n",
    "    predictions = model.predict(validation_generator)\n",
    "    \n",
    "    # Get the predicted class indices\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Get the true class labels\n",
    "    y_true = validation_generator.classes\n",
    "    \n",
    "    # Calculate accuracy, precision, recall, and F1 score\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating CNN model...\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 468ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data_Science_Projects\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate CNN model\n",
    "print(\"\\nEvaluating CNN model...\")\n",
    "cnn_accuracy, cnn_precision, cnn_recall, cnn_f1, cnn_cm = evaluate_model(cnn_model, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN Model Evaluation Metrics:\n",
      "Accuracy: 70.50%\n",
      "Precision: 0.71\n",
      "Recall: 0.70\n",
      "F1 Score: 0.68\n",
      "Confusion Matrix:\n",
      "[[ 54  56   9   0   0   0   0   0   0  10  12   0   8   0   0]\n",
      " [  3 211   0   0   0   0   0   0   0   0   0   0   7   0   0]\n",
      " [  1   0 138   1   0   0   1   4   0   1   0   0   0   0   4]\n",
      " [  5   4  10  13   0   1   2  55   1   7  26   2   6   0  18]\n",
      " [  1  18   0   0   0   0   0   0   0   0   0   3   0   0   0]\n",
      " [  0   2   0   0   0 273   1  10   0   1   0   0  29   0   3]\n",
      " [ 16   5   7   0   0  18  48  17   0   1  13   6  18   1   0]\n",
      " [ 26   7  15   1   0  16  10 155   4   9  17   0   9   0  17]\n",
      " [ 12   8   1   0   0   3   0   2  62  23   5   0  24   0   2]\n",
      " [  8  30  14   0   0   6   0   4  20 150   4  11   7   4   7]\n",
      " [  2   1   0   0   0   2   0   0   1   3 190  27  19   2   4]\n",
      " [  5   3   0   0   0   1   0   0   0   0  44 134   6   1  16]\n",
      " [  1   0   0   0   0  10   0   0   0   0   3   0 466   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   2   0   0   1  52   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   6   0   0 231]]\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics\n",
    "print(\"\\nCNN Model Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {cnn_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {cnn_precision:.2f}\")\n",
    "print(f\"Recall: {cnn_recall:.2f}\")\n",
    "print(f\"F1 Score: {cnn_f1:.2f}\")\n",
    "print(f\"Confusion Matrix:\\n{cnn_cm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MobileNet model...\n",
      "Epoch 1/5\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m728s\u001b[0m 2s/step - accuracy: 0.6779 - loss: 1.0451 - val_accuracy: 0.8444 - val_loss: 0.4773\n",
      "Epoch 2/5\n",
      "\u001b[1m  1/451\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:08\u001b[0m 953ms/step - accuracy: 0.8750 - loss: 0.3423"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wivan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.3423 - val_accuracy: 0.5000 - val_loss: 0.9944\n",
      "Epoch 3/5\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 1s/step - accuracy: 0.8890 - loss: 0.3462 - val_accuracy: 0.8968 - val_loss: 0.3179\n",
      "Epoch 4/5\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step - accuracy: 0.8438 - loss: 0.3541 - val_accuracy: 0.8125 - val_loss: 0.3224\n",
      "Epoch 5/5\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m717s\u001b[0m 2s/step - accuracy: 0.9057 - loss: 0.2687 - val_accuracy: 0.8926 - val_loss: 0.3119\n",
      "\n",
      "Evaluating MobileNet model...\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 925ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# MobileNet Model Function\n",
    "def build_mobilenet(input_shape, num_classes):\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Add global average pooling and dense layers\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    # Freeze base layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train MobileNet\n",
    "print(\"Training MobileNet model...\")\n",
    "\n",
    "# Build the MobileNet model\n",
    "mobilenet_model = build_mobilenet(input_shape=(224, 224, 3), num_classes=train_generator.num_classes)\n",
    "\n",
    "# Train the MobileNet model\n",
    "mobilenet_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=5  # Adjust this based on training performance\n",
    ")\n",
    "\n",
    "# Evaluate MobileNet model\n",
    "print(\"\\nEvaluating MobileNet model...\")\n",
    "mobilenet_accuracy, mobilenet_precision, mobilenet_recall, mobilenet_f1, mobilenet_cm = evaluate_model(mobilenet_model, validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for CNN:\n",
      "Accuracy: 70.50%\n",
      "Precision: 0.71\n",
      "Recall: 0.70\n",
      "F1 Score: 0.68\n",
      "Confusion Matrix:\n",
      "[[ 54  56   9   0   0   0   0   0   0  10  12   0   8   0   0]\n",
      " [  3 211   0   0   0   0   0   0   0   0   0   0   7   0   0]\n",
      " [  1   0 138   1   0   0   1   4   0   1   0   0   0   0   4]\n",
      " [  5   4  10  13   0   1   2  55   1   7  26   2   6   0  18]\n",
      " [  1  18   0   0   0   0   0   0   0   0   0   3   0   0   0]\n",
      " [  0   2   0   0   0 273   1  10   0   1   0   0  29   0   3]\n",
      " [ 16   5   7   0   0  18  48  17   0   1  13   6  18   1   0]\n",
      " [ 26   7  15   1   0  16  10 155   4   9  17   0   9   0  17]\n",
      " [ 12   8   1   0   0   3   0   2  62  23   5   0  24   0   2]\n",
      " [  8  30  14   0   0   6   0   4  20 150   4  11   7   4   7]\n",
      " [  2   1   0   0   0   2   0   0   1   3 190  27  19   2   4]\n",
      " [  5   3   0   0   0   1   0   0   0   0  44 134   6   1  16]\n",
      " [  1   0   0   0   0  10   0   0   0   0   3   0 466   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   2   0   0   1  52   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   6   0   0 231]]\n",
      "\n",
      "Results for MobileNet:\n",
      "Accuracy: 89.28%\n",
      "Precision: 0.91\n",
      "Recall: 0.89\n",
      "F1 Score: 0.89\n",
      "Confusion Matrix:\n",
      "[[148   0   0   0   0   0   0   1   0   0   0   0   0   0   0]\n",
      " [  3 217   0   0   0   0   0   1   0   0   0   0   0   0   0]\n",
      " [  1   0 138   8   0   0   0   2   0   1   0   0   0   0   0]\n",
      " [  0   0   0 125   1   0   0  23   0   1   0   0   0   0   0]\n",
      " [  0   0   0   3  19   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 313   0   0   0   4   0   0   2   0   0]\n",
      " [  2   0   1   0   0  12  87  34   2   7   3   0   2   0   0]\n",
      " [  0   0   0   0   0   0   0 282   1   1   2   0   0   0   0]\n",
      " [  0   0   0   0   0   4   0  19 114   1   3   0   0   1   0]\n",
      " [  0   0   0   0   0   7   5  20   3 229   1   0   0   0   0]\n",
      " [  0   0   0   0   0   3   1   7   2   2 230   3   3   0   0]\n",
      " [  0   0   0   0   0   8   6   9   0   2  43 140   2   0   0]\n",
      " [  0   0   0   0   0   6   0   1   2   2   1   0 468   0   0]\n",
      " [  0   0   0   0   0   0   0   3   1   2   2   0   4  43   0]\n",
      " [  0   0   0   0   0   1   0   3   0   0  19  11   0   0 204]]\n"
     ]
    }
   ],
   "source": [
    "# CNN Results\n",
    "print(\"\\nResults for CNN:\")\n",
    "print(f\"Accuracy: {cnn_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {cnn_precision:.2f}\")\n",
    "print(f\"Recall: {cnn_recall:.2f}\")\n",
    "print(f\"F1 Score: {cnn_f1:.2f}\")\n",
    "print(f\"Confusion Matrix:\\n{cnn_cm}\")\n",
    "\n",
    "# MobileNet Results\n",
    "print(\"\\nResults for MobileNet:\")\n",
    "print(f\"Accuracy: {mobilenet_accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {mobilenet_precision:.2f}\")\n",
    "print(f\"Recall: {mobilenet_recall:.2f}\")\n",
    "print(f\"F1 Score: {mobilenet_f1:.2f}\")\n",
    "print(f\"Confusion Matrix:\\n{mobilenet_cm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
